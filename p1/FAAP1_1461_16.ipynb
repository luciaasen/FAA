{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica 1 FAA\n",
    "======\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lucía Asencio y Alfonso Carvajal\n",
    "#### Grupo 1461, pareja 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Particionado\n",
    "----------------\n",
    "\n",
    "Para esta entrega hemos implementado dos estrategias de particionado, \n",
    "* Valicación __simple,__ y\n",
    "* Validación __cruzada__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación simple\n",
    "\n",
    "En el primer caso, el usuario escoge qué porcentaje de los datos va a ser usado para probar el modelo (el conjunto de test) y los datos restantes serán usados para entrenar el modelo. Esta validación conlleva por tanto una única partición de los datos.\n",
    "\n",
    "Para una consulta rápida, adjuntamos el código que crea las particiones en validación simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "    #Crea particiones segun el metodo tradicional de division de los datos segun el porcentaje deseado.\n",
    "    # Devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self,datos,seed=None):\n",
    "        # we assign a new value to seed only if it is None already\n",
    "        if seed == None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        # number of rows of the datos Matrix (number of inidvidual data)\n",
    "        totalRows = len(datos)\n",
    "        # Assuming porcentajeDeseado refers to the percentage of the data we want to save for testing\n",
    "        # we obtain the number of rows (data) to use for testing\n",
    "        testRows = int( (self.porcentajeDeseado * totalRows)/100 )\n",
    "        rows = list(range(0, totalRows))\n",
    "        random.shuffle(rows)\n",
    "        particionSimple = Particion()\n",
    "        # array size of totalRows - testRows\n",
    "        particionSimple.indicesTrain = rows[testRows :]\n",
    "        # array size of testRows\n",
    "        particionSimple.indicesTest = rows[: testRows]\n",
    "\n",
    "        self.listaParticiones.append(particionSimple)\n",
    "\n",
    "\n",
    "        return self.listaParticiones```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Lenses\n",
    "Comencemos viendo cómo la validación simple particiona los datos de las lentillas proporcionados para la práctica. A través del parámetro `porcentaje`, configuramos el porcentaje de datos que van destinados al conjunto de prueba. Consultamos en el objeto estrategia el número y estructura de la/s particiones creadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from plantillasArquitectura import Datos as d\n",
    "from plantillasArquitectura import EstrategiaParticionado as ep\n",
    "\n",
    "porcentaje = 25\n",
    "dataset = d.Datos('./plantillasArquitectura/datos/conjunto_datos_lentillas.txt')\n",
    "estrategia = ep.ValidacionSimple(porcentaje)\n",
    "listaParticiones = estrategia.creaParticiones(dataset.datos)\n",
    "\n",
    "print('Tal y como esperamos, la lista de particiones de la estrategia tiene longitud ', len(listaParticiones))\n",
    "print('\\nHay ', len(listaParticiones[0].indicesTrain), 'índices (más o menos el ',100-porcentaje,'% de ',len(dataset.datos),', que es el número de datos) destinados al entrenamiento del modelo, y son:')\n",
    "print(listaParticiones[0].indicesTrain)\n",
    "print('\\nLos ',len(listaParticiones[0].indicesTest),' índices restantes forman el conjunto de test: ')\n",
    "print(listaParticiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tic-tac-toe\n",
    "Como en este fichero hay mayor número de datos, imprimiremos simplemente el número de particiones (que, al ser validación simple, esperamos que sea uno), y el número de elementos de cada conjunto de la partición, para comprobar que se obtiene el porcentaje deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El fichero tic-tac-toe cuenta con un total de  958  datos\n",
      "La lista de particiones de la estrategia tiene longitud 1\n",
      "\n",
      "Hay  671 índices  en el conjunto de train, acorde con el  70 % esperado.\n",
      "Los  287 índices restantes forman el conjunto de test, un 30 % de los datos totales\n"
     ]
    }
   ],
   "source": [
    "porcentaje = 30\n",
    "dataset = d.Datos('./plantillasArquitectura/datos/tic-tac-toe.data')\n",
    "estrategia = ep.ValidacionSimple(porcentaje)\n",
    "listaParticiones = estrategia.creaParticiones(dataset.datos)\n",
    "\n",
    "print('El fichero tic-tac-toe cuenta con un total de ', len(dataset.datos),' datos')\n",
    "print('La lista de particiones de la estrategia tiene longitud', len(listaParticiones))\n",
    "print('\\nHay ', len(listaParticiones[0].indicesTrain), 'índices  en el conjunto de train, acorde con el ',100-porcentaje,'% esperado.')\n",
    "print('Los ',len(listaParticiones[0].indicesTest),'índices restantes forman el conjunto de test, un',porcentaje ,'% de los datos totales')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### German\n",
    "Debido a la longitud de los datos, hacemos la simplificación anterior. Además, vamos a comprobar que ambos conjuntos (train y test) son disjuntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El fichero cuenta con un total de  1000  datos\n",
      "La lista de particiones de la estrategia tiene longitud 1\n",
      "\n",
      "Hay  800 índices  en el conjunto de train, acorde con el  80 % esperado.\n",
      "Los  200 índices restantes forman el conjunto de test, un 20 % de los datos totales\n",
      "\n",
      "Por último, comprobamos el tamaño de la intersección de los conjuntos de train y test:  0\n"
     ]
    }
   ],
   "source": [
    "porcentaje = 20\n",
    "dataset = d.Datos('./plantillasArquitectura/datos/german.data')\n",
    "estrategia = ep.ValidacionSimple(porcentaje)\n",
    "listaParticiones = estrategia.creaParticiones(dataset.datos)\n",
    "\n",
    "print('El fichero cuenta con un total de ', len(dataset.datos),' datos')\n",
    "print('La lista de particiones de la estrategia tiene longitud', len(listaParticiones))\n",
    "print('\\nHay ', len(listaParticiones[0].indicesTrain), 'índices  en el conjunto de train, acorde con el ',100-porcentaje,'% esperado.')\n",
    "print('Los ',len(listaParticiones[0].indicesTest),'índices restantes forman el conjunto de test, un',porcentaje ,'% de los datos totales')\n",
    "set1 = set(listaParticiones[0].indicesTest)\n",
    "set2 = set(listaParticiones[0].indicesTrain)\n",
    "set3 = set1.intersection(set2)\n",
    "print('\\nPor último, comprobamos el tamaño de la intersección de los conjuntos de train y test: ', len(set3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada\n",
    "Si particionamos los datos usando validación cruzada, los datos se dividen en $K$ intervalos del mismo tamaño para evaluar el modelo. \n",
    "\n",
    "A lo largo de $K$ iteraciones, cada uno de estos K intervalos es usado una vez como conjunto de test, mientras los restantes $K-1$ conforman el conjunto de entrenamiento. Así, en cada iteración un error es calculado usando conjuntos de test y entrenamiento distintos, y el error final del modelo queda determinado por el error medio. En la implementación, este parámetro $K$ es elegido por el usuario.\n",
    "\n",
    "Comprobaremos cómo funciona mediante algunos ejemplos, pero primero mostramos el código según el cual se crean las particiones de validación cruzada.\n",
    "\n",
    "```python\n",
    "def creaParticiones(self,datos,seed=None):\n",
    "        # we assign a new value to seed only if it is None already\n",
    "        if seed == None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        # number of rows of the datos Matrix (number of inidvidual data)\n",
    "        totalRows = len(datos)\n",
    "        rows = list(range(0, totalRows))\n",
    "        random.shuffle(rows)\n",
    "        # number of rows in each partition (we take the integer part for the size of the test data)\n",
    "        partitionSize = int(totalRows / self.numeroParticiones)\n",
    "        for i in range(0, self.numeroParticiones):\n",
    "            particionCruzada = Particion()\n",
    "            test = rows[i * partitionSize : (i + 1) * partitionSize]\n",
    "            train = list(set(rows) - set(test))\n",
    "            particionCruzada.indicesTrain = train\n",
    "            particionCruzada.indicesTest = test\n",
    "            self.listaParticiones.append(particionCruzada)\n",
    "\n",
    "        return self.listaParticiones\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lenses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamos con  24 datos.\n",
      "La lista de particiones de la estrategia tiene longitud  5\n",
      "\n",
      "Para cada partición, vamos a imprimir el tamanio de los conjuntos de test y entrenamiento, y su suma.\n",
      "Esperariamos que cada tamanio fuera siempre el mismo, y que la suma fuera el numero total de datos\n",
      "Particion 1 :  4 + 20 = 24\n",
      "Particion 2 :  4 + 20 = 24\n",
      "Particion 3 :  4 + 20 = 24\n",
      "Particion 4 :  4 + 20 = 24\n",
      "Particion 5 :  4 + 20 = 24\n",
      "\n",
      "Como el conjunto de datos de lentillas es pequenio, vamos a imprimir los indices de test de cada particion, para ver que son realmente conjuntos distintos\n",
      "El conjunto de test  1 es [21, 5, 17, 16]\n",
      "El conjunto de test  2 es [4, 18, 3, 1]\n",
      "El conjunto de test  3 es [9, 13, 14, 0]\n",
      "El conjunto de test  4 es [10, 7, 15, 12]\n",
      "El conjunto de test  5 es [6, 19, 20, 23]\n",
      "\n",
      "Ademas, vamos a comprobar que los conjuntos de test son disjuntos dos a dos, para ver que la particion tiene la estructura deseada:\n",
      "La interseccion de los conjuntos de test 1 y 2 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 3 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 5 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 3 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 5 es vacia\n",
      "La interseccion de los conjuntos de test 3 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 3 y 5 es vacia\n",
      "La interseccion de los conjuntos de test 4 y 5 es vacia\n"
     ]
    }
   ],
   "source": [
    "nParticiones = 5\n",
    "dataset = d.Datos('./plantillasArquitectura/datos/conjunto_datos_lentillas.txt')\n",
    "estrategia = ep.ValidacionCruzada(nParticiones)\n",
    "listaParticiones = estrategia.creaParticiones(dataset.datos)\n",
    "\n",
    "print('Contamos con ', len(dataset.datos), 'datos.')\n",
    "print('La lista de particiones de la estrategia tiene longitud ', len(listaParticiones))\n",
    "print('\\nPara cada partición, vamos a imprimir el tamanio de los conjuntos de test y entrenamiento, y su suma.')\n",
    "print('Esperariamos que cada tamanio fuera siempre el mismo, y que la suma fuera el numero total de datos')\n",
    "for i in range(nParticiones):\n",
    "    sizeTrain = len(listaParticiones[i].indicesTrain)\n",
    "    sizeTest = len(listaParticiones[i].indicesTest)\n",
    "    print('Particion', i+1, ': ', sizeTest,'+', sizeTrain, '=' , sizeTest+sizeTrain)\n",
    "\n",
    "    \n",
    "print('\\nComo el conjunto de datos de lentillas es pequenio, vamos a imprimir los indices de test de cada particion, para ver que son realmente conjuntos distintos')\n",
    "for i in range(nParticiones):\n",
    "    print('El conjunto de test ', i+1, 'es', listaParticiones[i].indicesTest)\n",
    "\n",
    "print('\\nAdemas, vamos a comprobar que los conjuntos de test son disjuntos dos a dos, para ver que la particion tiene la estructura deseada:')\n",
    "for i in range(nParticiones):\n",
    "    for j in range(i+1, nParticiones):\n",
    "        set1 = set(listaParticiones[i].indicesTest)\n",
    "        set2 = set(listaParticiones[j].indicesTest)\n",
    "        set3 = set1.intersection(set2)\n",
    "        if(len(set3) == 0):\n",
    "            print('La interseccion de los conjuntos de test', i+1, 'y', j+1, 'es vacia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  German\n",
    "Para este conjunto, como es más grande, nos limitaremos a mostrar el tamaño de cada conjunto de cada partición (al igual que en el caso anterior), y a comprobar que las intersecciones de las distintos conjuntos de test son nulas, ya que son demasiado largos para imprimirlos uno a uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamos con  1000 datos.\n",
      "La lista de particiones de la estrategia tiene longitud  6\n",
      "\n",
      "Para cada partición, vamos a imprimir el tamanio de los conjuntos de test y entrenamiento, y su suma.\n",
      "Esperariamos que cada tamanio fuera siempre el mismo, y que la suma fuera el numero total de datos\n",
      "Particion 1 :  166 + 834 = 1000\n",
      "Particion 2 :  166 + 834 = 1000\n",
      "Particion 3 :  166 + 834 = 1000\n",
      "Particion 4 :  166 + 834 = 1000\n",
      "Particion 5 :  166 + 834 = 1000\n",
      "Particion 6 :  166 + 834 = 1000\n",
      "\n",
      "Ademas, vamos a comprobar que los conjuntos de test son disjuntos dos a dos, para ver que la particion tiene la estructura deseada:\n",
      "La interseccion de los conjuntos de test 1 y 2 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 3 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 5 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 6 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 3 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 5 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 6 es vacia\n",
      "La interseccion de los conjuntos de test 3 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 3 y 5 es vacia\n",
      "La interseccion de los conjuntos de test 3 y 6 es vacia\n",
      "La interseccion de los conjuntos de test 4 y 5 es vacia\n",
      "La interseccion de los conjuntos de test 4 y 6 es vacia\n",
      "La interseccion de los conjuntos de test 5 y 6 es vacia\n"
     ]
    }
   ],
   "source": [
    "nParticiones = 6\n",
    "dataset = d.Datos('./plantillasArquitectura/datos/german.data')\n",
    "estrategia = ep.ValidacionCruzada(nParticiones)\n",
    "listaParticiones = estrategia.creaParticiones(dataset.datos)\n",
    "\n",
    "print('Contamos con ', len(dataset.datos), 'datos.')\n",
    "print('La lista de particiones de la estrategia tiene longitud ', len(listaParticiones))\n",
    "print('\\nPara cada partición, vamos a imprimir el tamanio de los conjuntos de test y entrenamiento, y su suma.')\n",
    "print('Esperariamos que cada tamanio fuera siempre el mismo, y que la suma fuera el numero total de datos')\n",
    "for i in range(nParticiones):\n",
    "    sizeTrain = len(listaParticiones[i].indicesTrain)\n",
    "    sizeTest = len(listaParticiones[i].indicesTest)\n",
    "    print('Particion', i+1, ': ', sizeTest,'+', sizeTrain, '=' , sizeTest+sizeTrain)\n",
    "\n",
    "    \n",
    "print('\\nAdemas, vamos a comprobar que los conjuntos de test son disjuntos dos a dos, para ver que la particion tiene la estructura deseada:')\n",
    "for i in range(nParticiones):\n",
    "    for j in range(i+1, nParticiones):\n",
    "        set1 = set(listaParticiones[i].indicesTest)\n",
    "        set2 = set(listaParticiones[j].indicesTest)\n",
    "        set3 = set1.intersection(set2)\n",
    "        if(len(set3) == 0):\n",
    "            print('La interseccion de los conjuntos de test', i+1, 'y', j+1, 'es vacia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tic-tac-toe\n",
    "Procedemos de igual manera para el conjunto de datos tic-tac-toe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamos con  958 datos.\n",
      "La lista de particiones de la estrategia tiene longitud  4\n",
      "\n",
      "Para cada partición, vamos a imprimir el tamanio de los conjuntos de test y entrenamiento, y su suma.\n",
      "Esperariamos que cada tamanio fuera siempre el mismo, y que la suma fuera el numero total de datos\n",
      "Particion 1 :  239 + 719 = 958\n",
      "Particion 2 :  239 + 719 = 958\n",
      "Particion 3 :  239 + 719 = 958\n",
      "Particion 4 :  239 + 719 = 958\n",
      "\n",
      "Ademas, vamos a comprobar que los conjuntos de test son disjuntos dos a dos, para ver que la particion tiene la estructura deseada:\n",
      "La interseccion de los conjuntos de test 1 y 2 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 3 es vacia\n",
      "La interseccion de los conjuntos de test 1 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 3 es vacia\n",
      "La interseccion de los conjuntos de test 2 y 4 es vacia\n",
      "La interseccion de los conjuntos de test 3 y 4 es vacia\n"
     ]
    }
   ],
   "source": [
    "nParticiones = 4\n",
    "dataset = d.Datos('./plantillasArquitectura/datos/tic-tac-toe.data')\n",
    "estrategia = ep.ValidacionCruzada(nParticiones)\n",
    "listaParticiones = estrategia.creaParticiones(dataset.datos)\n",
    "\n",
    "print('Contamos con ', len(dataset.datos), 'datos.')\n",
    "print('La lista de particiones de la estrategia tiene longitud ', len(listaParticiones))\n",
    "print('\\nPara cada partición, vamos a imprimir el tamanio de los conjuntos de test y entrenamiento, y su suma.')\n",
    "print('Esperariamos que cada tamanio fuera siempre el mismo, y que la suma fuera el numero total de datos')\n",
    "for i in range(nParticiones):\n",
    "    sizeTrain = len(listaParticiones[i].indicesTrain)\n",
    "    sizeTest = len(listaParticiones[i].indicesTest)\n",
    "    print('Particion', i+1, ': ', sizeTest,'+', sizeTrain, '=' , sizeTest+sizeTrain)\n",
    "\n",
    "    \n",
    "print('\\nAdemas, vamos a comprobar que los conjuntos de test son disjuntos dos a dos, para ver que la particion tiene la estructura deseada:')\n",
    "for i in range(nParticiones):\n",
    "    for j in range(i+1, nParticiones):\n",
    "        set1 = set(listaParticiones[i].indicesTest)\n",
    "        set2 = set(listaParticiones[j].indicesTest)\n",
    "        set3 = set1.intersection(set2)\n",
    "        if(len(set3) == 0):\n",
    "            print('La interseccion de los conjuntos de test', i+1, 'y', j+1, 'es vacia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Conclusión (ventajas/desventajas)\n",
    "Tal y como se ha descrito, queda claro que el modelo de validación cruzada es más simple y computacionalmente menos costoso que la cruzada, de hecho, equivale a la estrategia de validación cruzada donde se ha configurado $K = 1$. \n",
    "\n",
    "En contraposición, el modelo de validación cruzada es más lento y costoso, ya que los datos son entrenados y evaluados $K$ veces en vez de una, y la complejidad de la validación crece linealmente con $K$ ya que, aunque el tamaño de las particiones disminuye, aumenta el número de entrenamientos a realizar.\n",
    "\n",
    "La principal ventaja de la validación cruzada es a su vez una desventaja de la simple. Cuando entrenamos $K$ veces y probamos sobre $K$ conjuntos distintos, conseguimos que el error del modelo devuelto por la validación sea más fiable. Evita que si, para un conjunto de test particular el modelo se ajusta muy, muy bien o muy, muy mal por pura casualidad, caigamos en el error que nuestro modelo es realmente muy bueno o muy malo. Al hacer la media de $K$ errores evitamos resultados de este estilo, ya que si tus $K$ conjuntos de test distintos que se ajustan fatal al modelo, es bastante improbable que esto sea casualidad, y seguramente ocurra que tu modelo es malo.\n",
    "\n",
    "Este pro de la cruzada explica precisamente la desventaja de la vaidación simple, donde al realizar un sólo test con un sólo conjunto de entrenamiento, no sabemos cómo de fiel es el error obtenido a la realidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Naive-Bayes\n",
    "___\n",
    "A continuación, realizaremos los tests necesarios para analizar nuestra implementación de Naive-Bayes.\n",
    "\n",
    "Extraemos información acerca de las tasas de error según los datos (lenses, german y toc-tac-toe), la estrategia de partición (cruzada o simple) aplicando diferentes parámetros (variamos $K$ y porcentajes) y si ha sido aplicada o no la corrección de Laplace. Cada prueba se realiza 15 veces para extraer luego media y varianza de la tasa de error obtenida.\n",
    "\n",
    "Además, vamos a separar la ejecución de german.data: debido a los altos tiempos de espera, no vamos a ejecutar validación cruzada con $K$ = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LENTILLAS\n",
      "\n",
      "v. simple, 20 %, Laplace a  True \n",
      "Error medio: 0.3078620916120916 \n",
      "Desviacion tipica: 0.06288431756892203\n",
      "\n",
      "v. simple, 20 %, Laplace a  False \n",
      "Error medio: 0.27875956231340593 \n",
      "Desviacion tipica: 0.010025629775761455\n",
      "\n",
      "v. simple, 30 %, Laplace a  True \n",
      "Error medio: 0.19270586556300842 \n",
      "Desviacion tipica: 0.07915396342924405\n",
      "\n",
      "v. simple, 30 %, Laplace a  False \n",
      "Error medio: 0.29501812636387975 \n",
      "Desviacion tipica: 0.0051280339073755685\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  True \n",
      "Error medio: 0.3442537185037185 \n",
      "Desviacion tipica: 0.0355484685450752\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  False \n",
      "Error medio: 0.3183124598009054 \n",
      "Desviacion tipica: 0.003029047492682565\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  True \n",
      "Error medio: 0.3245936655936656 \n",
      "Desviacion tipica: 0.03801324246898937\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  False \n",
      "Error medio: 0.3006856976149828 \n",
      "Desviacion tipica: 0.004700692364615092\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  True \n",
      "Error medio: 0.33028935262268594 \n",
      "Desviacion tipica: 0.00675542587942375\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  False \n",
      "Error medio: 0.30315928553954435 \n",
      "Desviacion tipica: 0.0044838029624860755\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  True \n",
      "Error medio: 0.30703355903355906 \n",
      "Desviacion tipica: 0.02131131178857696\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  False \n",
      "Error medio: 0.28830161678543703 \n",
      "Desviacion tipica: 0.001811625533310679\n",
      "\n",
      " TIC-TAC-TOE\n",
      "\n",
      "v. simple, 20 %, Laplace a  True \n",
      "Error medio: 0.30491295596007634 \n",
      "Desviacion tipica: 0.010942083182275212\n",
      "\n",
      "v. simple, 20 %, Laplace a  False \n",
      "Error medio: 0.2937562303505043 \n",
      "Desviacion tipica: 0.0015654006981358644\n",
      "\n",
      "v. simple, 30 %, Laplace a  True \n",
      "Error medio: 0.2940303798666168 \n",
      "Desviacion tipica: 0.008479022673464976\n",
      "\n",
      "v. simple, 30 %, Laplace a  False \n",
      "Error medio: 0.2901166827542507 \n",
      "Desviacion tipica: 0.00232512589738909\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  True \n",
      "Error medio: 0.3004118160296171 \n",
      "Desviacion tipica: 0.0008821479744545159\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  False \n",
      "Error medio: 0.29909542921581866 \n",
      "Desviacion tipica: 0.0003962339224794835\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  True \n",
      "Error medio: 0.3026256145414041 \n",
      "Desviacion tipica: 0.0010962158956078895\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  False \n",
      "Error medio: 0.30345513797134493 \n",
      "Desviacion tipica: 0.00014343819790848386\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  True \n",
      "Error medio: 0.3044452273182431 \n",
      "Desviacion tipica: 0.0008999866880776446\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  False \n",
      "Error medio: 0.30464339546304264 \n",
      "Desviacion tipica: 0.00019023630684045746\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  True \n",
      "Error medio: 0.30697417062842614 \n",
      "Desviacion tipica: 0.0013501792109135557\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  False \n",
      "Error medio: 0.3063516680267883 \n",
      "Desviacion tipica: 0.0003169600238563354\n"
     ]
    }
   ],
   "source": [
    "from plantillasArquitectura import Datos as d\n",
    "from plantillasArquitectura import EstrategiaParticionado as ep\n",
    "from plantillasArquitectura import Clasificador as cl\n",
    "import numpy as np\n",
    "nRepeticiones = 15\n",
    "\n",
    "dicc = dict()\n",
    "dicc['LENTILLAS'] = './plantillasArquitectura/datos/conjunto_datos_lentillas.txt'\n",
    "dicc['TIC-TAC-TOE'] = './plantillasArquitectura/datos/tic-tac-toe.data'\n",
    "\n",
    "for file in dicc:\n",
    "    dataset = d.Datos(dicc[file])\n",
    "    clasificador = cl.ClasificadorNaiveBayes()\n",
    "    print('\\n', file)\n",
    "    for j in range(2,4):\n",
    "        porcentaje = 10*j\n",
    "        estrategia = ep.ValidacionSimple(porcentaje)    \n",
    "        boolean = True\n",
    "        for i in range(2):\n",
    "            errores = np.array([clasificador.validacion(estrategia,dataset,clasificador, laplace = boolean) for k in range(nRepeticiones)])\n",
    "            mean, std = np.mean(errores), np.std(errores)\n",
    "            print('\\nv. simple,',porcentaje,'%, Laplace a ',boolean,'\\nError medio:', mean, '\\nDesviacion tipica:', std)\n",
    "            boolean = False\n",
    "\n",
    "    for i in range(5,25,5):\n",
    "        boolean = True\n",
    "        estrategia = ep.ValidacionCruzada(i)\n",
    "        for j in range(2):\n",
    "            errores = np.array([clasificador.validacion(estrategia,dataset,clasificador, laplace = boolean) for k in range(nRepeticiones)])\n",
    "            mean, std = np.mean(errores), np.std(errores)\n",
    "            print('\\nv.  cruzada, K =',i,', Laplace a ',boolean,'\\nError medio:', mean, '\\nDesviacion tipica:', std)\n",
    "            boolean = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GERMAN\n",
      "\n",
      "v. simple, 20 %, Laplace a  True \n",
      "Error medio: 0.23460110722610727 \n",
      "Desviacion tipica: 0.00952263697816008\n",
      "\n",
      "v. simple, 20 %, Laplace a  False \n",
      "Error medio: 0.2446694820323945 \n",
      "Desviacion tipica: 0.0011478083273373182\n",
      "\n",
      "v. simple, 30 %, Laplace a  True \n",
      "Error medio: 0.2576847664680998 \n",
      "Desviacion tipica: 0.004215858765510572\n",
      "\n",
      "v. simple, 30 %, Laplace a  False \n",
      "Error medio: 0.2520141059434448 \n",
      "Desviacion tipica: 0.0013129895377858606\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  True \n",
      "Error medio: 0.2518985492285494 \n",
      "Desviacion tipica: 0.000473868368093443\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  False \n",
      "Error medio: 0.2513488633324174 \n",
      "Desviacion tipica: 0.00022937065414628272\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  True \n",
      "Error medio: 0.2507002980352981 \n",
      "Desviacion tipica: 0.0009652189360731041\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  False \n",
      "Error medio: 0.24892872448140674 \n",
      "Desviacion tipica: 0.0002781312088348454\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  True \n",
      "Error medio: 0.24817009907413942 \n",
      "Desviacion tipica: 0.0027209664953959708\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  False \n",
      "Error medio: 0.24626081046399884 \n",
      "Desviacion tipica: 0.00031759519137716173\n"
     ]
    }
   ],
   "source": [
    "from plantillasArquitectura import Datos as d\n",
    "from plantillasArquitectura import EstrategiaParticionado as ep\n",
    "from plantillasArquitectura import Clasificador as cl\n",
    "import numpy as np\n",
    "nRepeticiones = 15\n",
    "\n",
    "dicc = dict()\n",
    "dicc['GERMAN'] = './plantillasArquitectura/datos/german.data'\n",
    "file = 'GERMAN'\n",
    "dataset = d.Datos(dicc[file])\n",
    "clasificador = cl.ClasificadorNaiveBayes()\n",
    "print('\\n', file)\n",
    "for j in range(2,4):\n",
    "    porcentaje = 10*j\n",
    "    estrategia = ep.ValidacionSimple(porcentaje)    \n",
    "    boolean = True\n",
    "    for i in range(2):\n",
    "        errores = np.array([clasificador.validacion(estrategia,dataset,clasificador, laplace = boolean) for k in range(nRepeticiones)])\n",
    "        mean, std = np.mean(errores), np.std(errores)\n",
    "        print('\\nv. simple,',porcentaje,'%, Laplace a ',boolean,'\\nError medio:', mean, '\\nDesviacion tipica:', std)\n",
    "        boolean = False\n",
    "\n",
    "for i in range(5,20,5):\n",
    "    boolean = True\n",
    "    estrategia = ep.ValidacionCruzada(i)\n",
    "    for j in range(2):\n",
    "        errores = np.array([clasificador.validacion(estrategia,dataset,clasificador, laplace = boolean) for k in range(nRepeticiones)])\n",
    "        mean, std = np.mean(errores), np.std(errores)\n",
    "        print('\\nv.  cruzada, K =',i,', Laplace a ',boolean,'\\nError medio:', mean, '\\nDesviacion tipica:', std)\n",
    "        boolean = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se muestra la tabla donde se reflejan los resultados de las pruebas.\n",
    "\n",
    "![alt text](https://github.com/luciaasen/FAA/blob/master/p1/tablas/NB_tables.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observaciones/ conclusiones\n",
    "* Sobre todo para el conjunto de latos lenses, podemos observar que la tendencia es que el modelo con corrección de Laplace sea más acertado que el modelo sin corrección. Para los otros dos ficheros apenas hay diferencia en los resultados: suponemos que esto se debe a que, al ser el número de datos mucho mayor, la corrección de Laplace ha de ser empleada en menos ocasiones y, cuando se utiliza, su efecto es menor debido también al número de ejemplos.\n",
    "\n",
    "* Comparando los distintos ficheros entre sí, parece que Naive-Bayes funciona ligeramente mejor con el fichero de german.data. Este hecho es razonable, ya que éste es el fichero que más datos distintos contiene, por lo cual en todos los casos el conjunto de entrenamiento es mayor. Además, es éste el fichero donde modelamos los atributos continuos como gaussianos. Puede que los resultados en este fichero sean mejores porque la distribución normal se ajusta muy bien al comportamiento de estos atributos.\n",
    "\n",
    "* Aunque esperábamos un mejor comportamiento usando la estrategia de validación cruzada que en validación simple, las tasas de error son más o menos las mismas, y de hecho a veces incluso más bajas en validación simple.\n",
    "\n",
    "* Lo que sí que hemos comprobado que disminuye en validación cruzada es la desviación típica. Cada uno de los errores con los que hemos calculado media y desviación proviene ya de una media de K errores, por lo que cualquier desviación grande de la media ha sido atenuada por la primera K-media. Es decir, es menos probable que el error de unna K-validación cruzada sea muy alto o muy bajo 'por casualidad', ya que esto querría decir que K errores han sido muy bajos o muy altos 'por casualidad' (poco probable). Es por esto que la desviación típica es menor en la validación cruzada.\n",
    "\n",
    "* En la mayoría de los casos, el error en validación simple con porcentaje 30% es ligeramente mayor que con porcentaje 20%. En cualquier caso ambos valores (que son los que hemos visto recomendados en más fuentes) trabajan bien. \n",
    "\n",
    "* Entre distintos valores de $K$, si miramos cada fila parece ser que el error disminuye a medida que aumenta $K$. Esto habla bien del modelo, porque indica que a pesar de estar probando muchos conjuntos de entrenamiento y test distintos, el error no crece sino que incluso disminuye. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n",
    "___\n",
    "Vamos a ejecutar pruebas similares al apartado anterior, esta vez usando las funciones para partición, entrenamiento y validación del módulo Scikit-Learn.  De nuevo, se varían diferentes estrategias y parámetros.\n",
    "\n",
    "En este caso, cada configuración es repetida 25 veces en vez de 15, ya scikit_learn trabajaba más rápido que nuestro código.\n",
    "\n",
    "Debido a la necesidad de discretizar parámetros (las funciones del módulo no nos permitían mezclar atributos discretos y continuos) y de realizar muchas llamadas a métodos de la librería (en nuestro caso, el número de llamadas era menor porque las funciones estaban 'envueltas' a nuestra conveniencia), el código de estas pruebas ocupaba el doble que las del apartado anterior y no lo adjuntaremos en el cuaderno. \n",
    "\n",
    "No obstante, el fichero de pruebas puede ser encontrado en el directorio de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LENTILLAS\n",
      "\n",
      "v. simple, 20.0 %, Laplace a  1.0 \n",
      "Error medio: 0.4000000000000001 \n",
      "Desviacion tipica: 5.551115123125783e-17\n",
      "\n",
      "v. simple, 20.0 %, Laplace a  1e-10 \n",
      "Error medio: 0.19999999999999996 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v. simple, 30.0 %, Laplace a  1.0 \n",
      "Error medio: 0.125 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v. simple, 30.0 %, Laplace a  1e-10 \n",
      "Error medio: 0.125 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  1.0 \n",
      "Error medio: 0.33000000000000007 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  1e-10 \n",
      "Error medio: 0.46000000000000013 \n",
      "Desviacion tipica: 5.551115123125783e-17\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  1.0 \n",
      "Error medio: 0.2333333333333334 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  1e-10 \n",
      "Error medio: 0.28333333333333344 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  1.0 \n",
      "Error medio: 0.23333333333333328 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  1e-10 \n",
      "Error medio: 0.2666666666666667 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  1.0 \n",
      "Error medio: 0.275 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  1e-10 \n",
      "Error medio: 0.32499999999999996 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      " TIC-TAC-TOE\n",
      "\n",
      "v. simple, 20.0 %, Laplace a  1.0 \n",
      "Error medio: 0.38541666666666663 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v. simple, 20.0 %, Laplace a  1e-10 \n",
      "Error medio: 0.38541666666666663 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v. simple, 30.0 %, Laplace a  1.0 \n",
      "Error medio: 0.41666666666666663 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v. simple, 30.0 %, Laplace a  1e-10 \n",
      "Error medio: 0.41666666666666663 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  1.0 \n",
      "Error medio: 0.4321389616055846 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  1e-10 \n",
      "Error medio: 0.4321389616055846 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  1.0 \n",
      "Error medio: 0.4165789473684211 \n",
      "Desviacion tipica: 5.551115123125783e-17\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  1e-10 \n",
      "Error medio: 0.4165789473684211 \n",
      "Desviacion tipica: 5.551115123125783e-17\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  1.0 \n",
      "Error medio: 0.4059854497354498 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  1e-10 \n",
      "Error medio: 0.4059854497354498 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  1.0 \n",
      "Error medio: 0.4030141843971631 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  1e-10 \n",
      "Error medio: 0.4030141843971631 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      " GERMAN\n",
      "\n",
      "v. simple, 20.0 %, Laplace a  1.0 \n",
      "Error medio: 0.36999999999999994 \n",
      "Desviacion tipica: 5.551115123125783e-17\n",
      "\n",
      "v. simple, 20.0 %, Laplace a  1e-10 \n",
      "Error medio: 0.36 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v. simple, 30.0 %, Laplace a  1.0 \n",
      "Error medio: 0.32333333333333336 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v. simple, 30.0 %, Laplace a  1e-10 \n",
      "Error medio: 0.32666666666666666 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  1.0 \n",
      "Error medio: 0.31899999999999995 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 5 , Laplace a  1e-10 \n",
      "Error medio: 0.31699999999999995 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  1.0 \n",
      "Error medio: 0.31699999999999995 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 10 , Laplace a  1e-10 \n",
      "Error medio: 0.31599999999999995 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  1.0 \n",
      "Error medio: 0.31775968641640284 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 15 , Laplace a  1e-10 \n",
      "Error medio: 0.31575456053067985 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  1.0 \n",
      "Error medio: 0.3190000000000002 \n",
      "Desviacion tipica: 0.0\n",
      "\n",
      "v.  cruzada, K = 20 , Laplace a  1e-10 \n",
      "Error medio: 0.32000000000000006 \n",
      "Desviacion tipica: 0.0\n"
     ]
    }
   ],
   "source": [
    "import prueba_scikit\n",
    "prueba_scikit.pruebaScikit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que en esta tabla **se ha omitido la desviación típica**, por ser esta valores muy cercanos a cero en todas las iteraciones. Las desviaciones eran o nulas o del orden de $10^{-17}$ en todos los casos.\n",
    "\n",
    "![alt text](https://github.com/luciaasen/FAA/blob/master/p1/tablas/scikit_tables.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observaciones/conclusiones\n",
    "Analicemos rápidamente los resultados que reflejan esta tabla:\n",
    "* En este caso, justo al contrario que en el anterior, el modelo parece tener más errores a medida que crece el conjunto de datos: las tasas son más bajas para el conjunto de las lentillas. Creemos que esto podría deberse a la discretización que forzamos en los atributos.\n",
    "* Acerca de Laplace, pasa lo mismo que en el análisis del apartado anterior. La corrección apenas afecta a los ficheros grandes sea cual sea la estrategia, mientras que sí que marca diferencias en el fichero de lentillas. Como ya hemos comentado, cuando las particiones tienen pocos datos es más probable que haya que aplicarla, y que cuando se aplique tenga una consecuencia más notable. Además, excepto en un caso, el modelo con corrección funciona igual o mejor que el que no tiene corrección.\n",
    "* En este caso no llegamos a una conclusión clara acerca de qué porcentaje es mejor en validación simple, ya que depende de una instancia a otra.\n",
    "* Para los casos estudiados, $K = 15$ parece ser la decisión acertada. Es aquí donde parece que se alcanza el mínimo de tasa de error, ya que para $K = 5, 10$ es mayor, y para $K = 20$ vuelve a crecer en todos los casos.\n",
    "* Lo más destacable de esta prueba es lo bajas que eran las desviaciones típicas de cada conjunto de validaciones. Hemos repetido la prueba varias veces y la desviación típica es siempre casi nula. Teorizamos que esto podría ser debido a la discretización, y por tanto a lo mejor sobresimplificación, de los datos.\n",
    "* En comparación con nuestra implementación Naive-Bayes, esta parece (para nuestra sorpresa) ser menos exacta: la tasa de error es, en general, mayor con Scikit. En contraposición, la ejecución con Scikit ha sido muchísimo más rápida que con nuestra implementación. La otra gran diferencia está en las desviaciones típicas, mucho más bajas en el últim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
