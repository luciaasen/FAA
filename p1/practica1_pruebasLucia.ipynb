{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantillasArquitectura import Datos as d\n",
    "from scipy.stats import norm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenses = d.Datos('./plantillasArquitectura/datos/conjunto_datos_lentillas.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Spectacle', 'Astigmatic', 'Tear', 'Class']\n",
      "['Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal']\n",
      "[True, True, True, True, True]\n",
      "[{'1': 0, '2': 1, '3': 2}, {'1': 0, '2': 1}, {'1': 0, '2': 1}, {'1': 0, '2': 1}, {'1': 0, '2': 1, '3': 2}]\n",
      "[[0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 1. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 2.]\n",
      " [0. 1. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 2.]\n",
      " [1. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 2.]\n",
      " [1. 0. 1. 1. 0.]\n",
      " [1. 1. 0. 0. 2.]\n",
      " [1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 0. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [2. 0. 0. 0. 2.]\n",
      " [2. 0. 0. 1. 2.]\n",
      " [2. 0. 1. 0. 2.]\n",
      " [2. 0. 1. 1. 0.]\n",
      " [2. 1. 0. 0. 2.]\n",
      " [2. 1. 0. 1. 1.]\n",
      " [2. 1. 1. 0. 2.]\n",
      " [2. 1. 1. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "lenses.datos\n",
    "datosTrain=lenses.datos\n",
    "atributosDiscretos = lenses.nominalAtributos\n",
    "print(lenses.nombreAtributos)\n",
    "print(lenses.tipoAtributos)\n",
    "print(lenses.nominalAtributos)\n",
    "print(lenses.diccionarios)\n",
    "print(lenses.datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      "0.752843580387011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.752843580387011"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prioris = dict()\n",
    "nDatos = len(datosTrain)\n",
    "classIdx = np.size(datosTrain,1)-1 \n",
    "for dato in datosTrain:\n",
    "    clase = dato[classIdx]\n",
    "    if clase not in prioris.keys():\n",
    "        prioris[clase] = 1/nDatos\n",
    "    else :\n",
    "        prioris[clase] += 1/nDatos\n",
    "classes = list((datosTrain[:, -1]))\n",
    "third = list(set(datosTrain[:, 2]))\n",
    "\n",
    "filteredColumn = datosTrain[datosTrain[:,-1]==classes[0]][:,3]\n",
    "print(filteredColumn)\n",
    "mean = np.mean(filteredColumn)\n",
    "std = np.std(filteredColumn)\n",
    "gen = norm(mean, std)\n",
    "print(gen.pdf(0.5))                \n",
    "np.sum((datosTrain[:,2]==third[0] ) & (datosTrain[:,-1]==classes[0]))\n",
    "gen.pdf(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# There are len - 1 attributes, since last element in atributosDiscretos, the class, does not correspond to an attribute\n",
    "nAtributos = len(atributosDiscretos)-1\n",
    "# We extract a set with all classes in the data\n",
    "classes = set(datosTrain[:, -1])\n",
    "\n",
    "# We create a list where each element of the list corresponds to the i-th attribute,\n",
    "# and for each attribute a dictionary with classes as keys is created\n",
    "# If the attribute is continuous, then for each class key the appropriate normal distribution is assigned as a value\n",
    "# Otherwise, for each class key a new dictionary is created, which has the attribute values as keys,\n",
    "#            and for each value key,the number of data elements with the current class and current value is assigned as value\n",
    "\n",
    "attrTables = []\n",
    "for i in range(nAtributos-1):\n",
    "        # For each attribute, a dictionary with all classes as values\n",
    "        classesTable = dict()\n",
    "            \n",
    "        for clase in classes:\n",
    "            # We extract a set with all attribute values for the i-th attribute\n",
    "            attrValues = set(datosTrain[:,i])\n",
    "            # If i-th attribute discrete:\n",
    "            # For each class, a dictionary with the i-th attribute values as keys\n",
    "            classesTable[clase] = dict()            \n",
    "            if(atributosDiscretos[i]):\n",
    "                for value in attrValues:\n",
    "                    # We count the number of elements of class clase out of the elements \n",
    "                    # where the i-th attribute has value value\n",
    "                    count = np.sum((datosTrain[:,i]==value ) & (datosTrain[:,-1]==clase))\n",
    "                    #if count == 0: \n",
    "                    #    AQUI SE HARIA LAPLACE: activar una flag que, una vez recorridos todos los values, sume uno a todos los dics\n",
    "                    #    Ineficiente a tope pero al menos no es larguisimo, nValuesxNclasses no deberia ser un valor muy grande    \n",
    "                    classesTable[clase][value] = count\n",
    "\n",
    "            # If i-th attribute continuous:\n",
    "            else:\n",
    "                # We create an array with the i-th attribute values of data where class == clase\n",
    "                filteredColumn = datosTrain[datosTrain[:,-1]==clase][:, i]\n",
    "                # We extract mean and variance of the i-th column\n",
    "                mean = np.mean(filteredColumn)\n",
    "                std = np.std(filteredColumn)\n",
    "                classesTable[clase] = norm(mean, std)\n",
    "                \n",
    "        attrTables.append(classesTable)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 1. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 2.]\n",
      " [0. 1. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 2.]\n",
      " [1. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 2.]\n",
      " [1. 0. 1. 1. 0.]\n",
      " [1. 1. 0. 0. 2.]\n",
      " [1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 0. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [2. 0. 0. 0. 2.]\n",
      " [2. 0. 0. 1. 2.]\n",
      " [2. 0. 1. 0. 2.]\n",
      " [2. 0. 1. 1. 0.]\n",
      " [2. 1. 0. 0. 2.]\n",
      " [2. 1. 0. 1. 1.]\n",
      " [2. 1. 1. 0. 2.]\n",
      " [2. 1. 1. 1. 2.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{0.0: {0.0: 2, 1.0: 1, 2.0: 1},\n",
       "  1.0: {0.0: 2, 1.0: 2, 2.0: 1},\n",
       "  2.0: {0.0: 4, 1.0: 5, 2.0: 6}},\n",
       " {0.0: {0.0: 3, 1.0: 1}, 1.0: {0.0: 2, 1.0: 3}, 2.0: {0.0: 7, 1.0: 8}},\n",
       " {0.0: {0.0: 0, 1.0: 4}, 1.0: {0.0: 5, 1.0: 0}, 2.0: {0.0: 7, 1.0: 8}}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lenses.datos)\n",
    "attrTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
