{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantillasArquitectura import Datos as d\n",
    "from scipy.stats import norm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenses = d.Datos('./plantillasArquitectura/datos/conjunto_datos_lentillas.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Spectacle', 'Astigmatic', 'Tear', 'Class']\n",
      "['Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal']\n",
      "[True, True, True, True, True]\n",
      "[{'1': 0, '2': 1, '3': 2}, {'1': 0, '2': 1}, {'1': 0, '2': 1}, {'1': 0, '2': 1}, {'1': 0, '2': 1, '3': 2}]\n",
      "[[0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 2.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 2.]\n",
      " [0. 1. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 2.]\n",
      " [0. 1. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 2.]\n",
      " [1. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 2.]\n",
      " [1. 0. 1. 1. 0.]\n",
      " [1. 1. 0. 0. 2.]\n",
      " [1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 0. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [2. 0. 0. 0. 2.]\n",
      " [2. 0. 0. 1. 2.]\n",
      " [2. 0. 1. 0. 2.]\n",
      " [2. 0. 1. 1. 0.]\n",
      " [2. 1. 0. 0. 2.]\n",
      " [2. 1. 0. 1. 1.]\n",
      " [2. 1. 1. 0. 2.]\n",
      " [2. 1. 1. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "lenses.datos\n",
    "datosTrain=lenses.datos\n",
    "atributosDiscretos = lenses.nominalAtributos\n",
    "print(lenses.nombreAtributos)\n",
    "print(lenses.tipoAtributos)\n",
    "print(lenses.nominalAtributos)\n",
    "print(lenses.diccionarios)\n",
    "print(lenses.datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '2': 1, '3': 2}\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-400c617ec002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlenses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiccionarios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiccionarios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keys' is not defined"
     ]
    }
   ],
   "source": [
    "print(lenses.diccionarios[-1])\n",
    "for key in lenses.diccionarios[-1]:\n",
    "    print(key)\n",
    "print(lenses.diccionarios[-1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 5)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      "0.752843580387011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datosTrain.shape)\n",
    "print(type(datosTrain))\n",
    "prioris = dict()\n",
    "nDatos = len(datosTrain)\n",
    "classIdx = np.size(datosTrain,1)-1 \n",
    "for dato in datosTrain:\n",
    "    clase = dato[classIdx]\n",
    "    if clase not in prioris.keys():\n",
    "        prioris[clase] = 1/nDatos\n",
    "    else :\n",
    "        prioris[clase] += 1/nDatos\n",
    "classes = list((datosTrain[:, -1]))\n",
    "third = list(set(datosTrain[:, 2]))\n",
    "\n",
    "filteredColumn = datosTrain[datosTrain[:,-1]==classes[0]][:,3]\n",
    "print(filteredColumn)\n",
    "mean = np.mean(filteredColumn)\n",
    "std = np.std(filteredColumn)\n",
    "gen = norm(mean, std)\n",
    "print(gen.pdf(0.5))                \n",
    "np.sum((datosTrain[:,2]==third[0] ) & (datosTrain[:,-1]==classes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize the posteriori numerator as the priori probability for clase\n",
    "    verodotpriori = 1\n",
    "    # Initialize the posteriori numerator as the priori probability for clase\n",
    "    verodotpriori = 1\n",
    "    # Initialize the posteriori numerator as the priori probability for clase\n",
    "    verodotpriori = 1\n",
    "    # Initialize the posteriori numerator as the priori probability for clase\n",
    "    verodotpriori = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# There are len - 1 attributes, since last element in atributosDiscretos, the class, does not correspond to an attribute\n",
    "nAtributos = len(atributosDiscretos)-1\n",
    "# We extract a set with all classes in the data\n",
    "classes = set(datosTrain[:, -1])\n",
    "\n",
    "# We create a list where each element of the list corresponds to the i-th attribute,\n",
    "# and for each attribute a dictionary with classes as keys is created\n",
    "# If the attribute is continuous, then for each class key the appropriate normal distribution is assigned as a value\n",
    "# Otherwise, for each class key a new dictionary is created, which has the attribute values as keys,\n",
    "#            and for each value key,the number of data elements with the current class and current value is assigned as value\n",
    "\n",
    "attrTables = []\n",
    "for i in range(nAtributos-1):\n",
    "        # For each attribute, a dictionary with all classes as values\n",
    "        classesTable = dict()\n",
    "            \n",
    "        for clase in classes:\n",
    "            # We extract a set with all attribute values for the i-th attribute\n",
    "            attrValues = set(datosTrain[:,i])\n",
    "            # If i-th attribute discrete:\n",
    "            # For each class, a dictionary with the i-th attribute values as keys\n",
    "            classesTable[clase] = dict()            \n",
    "            if(atributosDiscretos[i]):\n",
    "                for value in attrValues:\n",
    "                    # We count the number of elements of class clase out of the elements \n",
    "                    # where the i-th attribute has value value\n",
    "                    count = np.sum((datosTrain[:,i]==value ) & (datosTrain[:,-1]==clase))\n",
    "                    #if count == 0: \n",
    "                    #    AQUI SE HARIA LAPLACE: activar una flag que, una vez recorridos todos los values, sume uno a todos los dics\n",
    "                    #    Ineficiente a tope pero al menos no es larguisimo, nValuesxNclasses no deberia ser un valor muy grande    \n",
    "                    classesTable[clase][value] = count\n",
    "\n",
    "            # If i-th attribute continuous:\n",
    "            else:\n",
    "                # We create an array with the i-th attribute values of data where class == clase\n",
    "                filteredColumn = datosTrain[datosTrain[:,-1]==clase][:, i]\n",
    "                # We extract mean and variance of the i-th column\n",
    "                mean = np.mean(filteredColumn)\n",
    "                std = np.std(filteredColumn)\n",
    "                classesTable[clase] = norm(mean, std)\n",
    "                \n",
    "        attrTables.append(classesTable)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBTables = attrTables\n",
    "prioris\n",
    "sum(attrTables[0][2].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = lenses.datos\n",
    "\n",
    "pred = []\n",
    "for data in testData:\n",
    "    maxClass = [clase, 0]\n",
    "    for clase in classes:    \n",
    "        # Initialize the posteriori numerator as the priori probability for clase\n",
    "        verodotpriori = prioris[clase]\n",
    "        # Now we multiply by each P(attrN == valueofattrNindata | clase)\n",
    "        nAtributos = len(atributosDiscretos)-1\n",
    "        for i in range(nAtributos-1):\n",
    "            # Value of the i-th attribute in the given testData element \n",
    "            value = data[i]\n",
    "            # We search in NBTables: \n",
    "            # take the i-th position of the array, corresponding to the dictionary of the i-th attribute\n",
    "            if atributosDiscretos[i]:\n",
    "                # inside, if the attribute is discrete, the dictionary corresponding to the 'clase' key \n",
    "                # and from there, the key 'value' (which is number of occurrences of class = clase and ithattribute = value)\n",
    "                nOccurrences = NBTables[i][clase][value]\n",
    "                # And divide by the number of occurrences of the other values given class = clase\n",
    "                vero = nOccurrences/sum(attrTables[i][clase].values())\n",
    "            else :\n",
    "                # if the attribute is continuous, take the distribution stored in the 'clase' key\n",
    "                # and calculate the pdf of the ith attribute being the value that our testData element has\n",
    "                vero = NBTables[i][clase].pdf(value)\n",
    "            verodotpriori *= vero\n",
    "        \n",
    "        # If the last calculated numerator is greater than the previous max, update the class and its numerator\n",
    "        if verodotpriori > maxClass[1]:\n",
    "            maxClass = [clase, verodotpriori]\n",
    "    # We append to the pred array the class predicted for the testData element we are testing\n",
    "    pred.append(maxClass[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
